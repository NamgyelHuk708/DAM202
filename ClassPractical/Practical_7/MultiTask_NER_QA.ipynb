{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc807982",
   "metadata": {},
   "source": [
    "# Multi-Task Learning: NER + QA with Shared BERT Encoder\n",
    "\n",
    "**Course:** DAM202 [Year3-Sem1] - Practical 7\n",
    "\n",
    "**Project Goal:** Build a single Transformer model that performs both Named Entity Recognition (NER) and Question Answering (QA) using hard parameter sharing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f475c",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation\n",
    "\n",
    "First, let's check GPU availability and install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82816dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets seqeval accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec5ec23",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For evaluation\n",
    "from seqeval.metrics import f1_score as ner_f1_score\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6827c2",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Datasets\n",
    "\n",
    "We'll use:\n",
    "- **CoNLL-2003** for NER - Loading from Parquet files (modern format)\n",
    "- **SQuAD v1.1** for QA\n",
    "\n",
    "**Important:** The `datasets` library deprecated Python loading scripts. We now load directly from Parquet files using the `hf://` protocol or pre-converted versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f6d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets - Using Parquet exports (no loading scripts)\n",
    "print(\"Loading CoNLL-2003 dataset for NER...\")\n",
    "# Use the Parquet export generated by Hugging Face\n",
    "# This bypasses the deprecated loading script\n",
    "from datasets import load_dataset_builder\n",
    "\n",
    "# Try loading with builder to get Parquet files\n",
    "try:\n",
    "    # Method 1: Use Parquet files directly\n",
    "    ner_dataset = load_dataset(\n",
    "        \"parquet\",\n",
    "        data_files={\n",
    "            \"train\": \"hf://datasets/conll2003/data/train-00000-of-00001.parquet\",\n",
    "            \"validation\": \"hf://datasets/conll2003/data/validation-00000-of-00001.parquet\",\n",
    "            \"test\": \"hf://datasets/conll2003/data/test-00000-of-00001.parquet\"\n",
    "        }\n",
    "    )\n",
    "    print(\"‚úì Loaded CoNLL-2003 from Parquet files\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading from Parquet: {e}\")\n",
    "    print(\"Trying alternative method...\")\n",
    "    # Fallback: use a pre-converted version\n",
    "    ner_dataset = load_dataset(\"lhoestq/conll2003\")\n",
    "\n",
    "print(\"\\nLoading SQuAD dataset for QA...\")\n",
    "qa_dataset = load_dataset(\"squad\")\n",
    "\n",
    "print(\"\\n=== NER Dataset Info ===\")\n",
    "print(ner_dataset)\n",
    "print(\"\\nSample NER example:\")\n",
    "print(ner_dataset['train'][0])\n",
    "\n",
    "print(\"\\n=== QA Dataset Info ===\")\n",
    "print(qa_dataset)\n",
    "print(\"\\nSample QA example:\")\n",
    "print(qa_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9498a",
   "metadata": {},
   "source": [
    "## 4. NER Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NER label list\n",
    "# Handle different dataset structures (original vs Parquet)\n",
    "try:\n",
    "    # Try original structure first\n",
    "    ner_label_list = ner_dataset['train'].features['ner_tags'].feature.names\n",
    "except AttributeError:\n",
    "    # Fallback: manually define CoNLL-2003 NER labels (IOB format)\n",
    "    # Standard CoNLL-2003 labels\n",
    "    ner_label_list = [\n",
    "        'O',           # Outside any named entity\n",
    "        'B-PER',       # Beginning of a person name\n",
    "        'I-PER',       # Inside a person name\n",
    "        'B-ORG',       # Beginning of an organization\n",
    "        'I-ORG',       # Inside an organization\n",
    "        'B-LOC',       # Beginning of a location\n",
    "        'I-LOC',       # Inside a location\n",
    "        'B-MISC',      # Beginning of miscellaneous entity\n",
    "        'I-MISC'       # Inside miscellaneous entity\n",
    "    ]\n",
    "    print(\"Using standard CoNLL-2003 NER labels\")\n",
    "\n",
    "num_ner_labels = len(ner_label_list)\n",
    "\n",
    "print(f\"\\nNER Labels ({num_ner_labels} total):\")\n",
    "for idx, label in enumerate(ner_label_list):\n",
    "    print(f\"{idx}: {label}\")\n",
    "\n",
    "# Create label mappings\n",
    "id2label = {i: label for i, label in enumerate(ner_label_list)}\n",
    "label2id = {label: i for i, label in enumerate(ner_label_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e485c",
   "metadata": {},
   "source": [
    "## 5. Initialize Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "print(f\"Tokenizer loaded: {model_checkpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b9a669",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing Functions\n",
    "\n",
    "### 6.1 NER Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a127d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenize NER data and align labels with subword tokens.\n",
    "    Use -100 for subword tokens that should be ignored in loss calculation.\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['tokens'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        \n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For other tokens in a word, set label to -100\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = torch.tensor(labels)\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing NER preprocessing...\")\n",
    "sample = ner_dataset['train'][:2]\n",
    "processed = tokenize_and_align_labels(sample)\n",
    "print(f\"Input IDs shape: {processed['input_ids'].shape}\")\n",
    "print(f\"Labels shape: {processed['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b5b49",
   "metadata": {},
   "source": [
    "### 6.2 QA Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_qa_examples(examples, max_length=384, doc_stride=128):\n",
    "    \"\"\"\n",
    "    Preprocess QA data: tokenize question + context and find answer spans.\n",
    "    \"\"\"\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    contexts = examples[\"context\"]\n",
    "    \n",
    "    # Tokenize with truncation and padding\n",
    "    tokenized_examples = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Get sample mapping to handle overflowing tokens\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    \n",
    "    # Initialize start and end positions\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        sample_idx = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_idx]\n",
    "        \n",
    "        # If no answers, set positions to 0 (CLS token)\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            continue\n",
    "        \n",
    "        # Get the answer span\n",
    "        start_char = answers[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answers[\"text\"][0])\n",
    "        \n",
    "        # Find token positions corresponding to answer\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        \n",
    "        # Find start and end of context\n",
    "        context_start = 0\n",
    "        while sequence_ids[context_start] != 1:\n",
    "            context_start += 1\n",
    "        context_end = len(sequence_ids) - 1\n",
    "        while sequence_ids[context_end] != 1:\n",
    "            context_end -= 1\n",
    "        \n",
    "        # If answer is not in this chunk, set to CLS\n",
    "        if not (offsets[context_start][0] <= start_char and offsets[context_end][1] >= end_char):\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Find start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offsets[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "            \n",
    "            idx = context_end\n",
    "            while idx >= context_start and offsets[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "    \n",
    "    tokenized_examples[\"start_positions\"] = torch.tensor(start_positions)\n",
    "    tokenized_examples[\"end_positions\"] = torch.tensor(end_positions)\n",
    "    \n",
    "    return tokenized_examples\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing QA preprocessing...\")\n",
    "qa_sample = qa_dataset['train'][:2]\n",
    "qa_processed = preprocess_qa_examples(qa_sample)\n",
    "print(f\"Input IDs shape: {qa_processed['input_ids'].shape}\")\n",
    "print(f\"Start positions shape: {qa_processed['start_positions'].shape}\")\n",
    "print(f\"End positions shape: {qa_processed['end_positions'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3cd23d",
   "metadata": {},
   "source": [
    "## 7. Create Processed Datasets\n",
    "\n",
    "For efficiency in this practical, we'll use a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496eed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subset for faster training (adjust as needed)\n",
    "TRAIN_SAMPLES_NER = 2000\n",
    "TRAIN_SAMPLES_QA = 2000\n",
    "VAL_SAMPLES = 500\n",
    "\n",
    "# Prepare NER datasets\n",
    "print(\"Processing NER training data...\")\n",
    "ner_train_subset = ner_dataset['train'].select(range(TRAIN_SAMPLES_NER))\n",
    "ner_val_subset = ner_dataset['validation'].select(range(VAL_SAMPLES))\n",
    "\n",
    "# Prepare QA datasets\n",
    "print(\"Processing QA training data...\")\n",
    "qa_train_subset = qa_dataset['train'].select(range(TRAIN_SAMPLES_QA))\n",
    "qa_val_subset = qa_dataset['validation'].select(range(VAL_SAMPLES))\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"NER Train: {len(ner_train_subset)}, Val: {len(ner_val_subset)}\")\n",
    "print(f\"QA Train: {len(qa_train_subset)}, Val: {len(qa_val_subset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbef871",
   "metadata": {},
   "source": [
    "## 8. Custom Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer, max_length=128):\n",
    "        self.data = []\n",
    "        \n",
    "        # Process in batches for efficiency\n",
    "        batch_size = 32\n",
    "        for i in tqdm(range(0, len(hf_dataset), batch_size), desc=\"Processing NER data\"):\n",
    "            batch = hf_dataset[i:min(i+batch_size, len(hf_dataset))]\n",
    "            processed = tokenize_and_align_labels(batch, max_length)\n",
    "            \n",
    "            for j in range(len(processed['input_ids'])):\n",
    "                self.data.append({\n",
    "                    'input_ids': processed['input_ids'][j],\n",
    "                    'attention_mask': processed['attention_mask'][j],\n",
    "                    'labels': processed['labels'][j],\n",
    "                    'task': 'ner'\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer, max_length=384):\n",
    "        self.data = []\n",
    "        \n",
    "        # Process in batches\n",
    "        batch_size = 16\n",
    "        for i in tqdm(range(0, len(hf_dataset), batch_size), desc=\"Processing QA data\"):\n",
    "            batch = hf_dataset[i:min(i+batch_size, len(hf_dataset))]\n",
    "            processed = preprocess_qa_examples(batch, max_length)\n",
    "            \n",
    "            for j in range(len(processed['input_ids'])):\n",
    "                self.data.append({\n",
    "                    'input_ids': processed['input_ids'][j],\n",
    "                    'attention_mask': processed['attention_mask'][j],\n",
    "                    'start_positions': processed['start_positions'][j],\n",
    "                    'end_positions': processed['end_positions'][j],\n",
    "                    'task': 'qa'\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating NER datasets...\")\n",
    "ner_train_dataset = NERDataset(ner_train_subset, tokenizer)\n",
    "ner_val_dataset = NERDataset(ner_val_subset, tokenizer)\n",
    "\n",
    "print(\"\\nCreating QA datasets...\")\n",
    "qa_train_dataset = QADataset(qa_train_subset, tokenizer)\n",
    "qa_val_dataset = QADataset(qa_val_subset, tokenizer)\n",
    "\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"NER Train: {len(ner_train_dataset)}, Val: {len(ner_val_dataset)}\")\n",
    "print(f\"QA Train: {len(qa_train_dataset)}, Val: {len(qa_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648bd40",
   "metadata": {},
   "source": [
    "## 9. Multi-Task DataLoader\n",
    "\n",
    "Custom dataloader that alternates between NER and QA batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d45dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataLoader:\n",
    "    def __init__(self, ner_dataset, qa_dataset, batch_size=16, shuffle=True):\n",
    "        self.ner_loader = DataLoader(ner_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        self.qa_loader = DataLoader(qa_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        \n",
    "        self.ner_iter = iter(self.ner_loader)\n",
    "        self.qa_iter = iter(self.qa_loader)\n",
    "        \n",
    "        # Calculate total batches (sum of both tasks)\n",
    "        self.total_batches = len(self.ner_loader) + len(self.qa_loader)\n",
    "        self.current_batch = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.ner_iter = iter(self.ner_loader)\n",
    "        self.qa_iter = iter(self.qa_loader)\n",
    "        self.current_batch = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current_batch >= self.total_batches:\n",
    "            raise StopIteration\n",
    "        \n",
    "        # Alternate between tasks (Round-Robin)\n",
    "        if self.current_batch % 2 == 0:\n",
    "            try:\n",
    "                batch = next(self.ner_iter)\n",
    "            except StopIteration:\n",
    "                batch = next(self.qa_iter)\n",
    "        else:\n",
    "            try:\n",
    "                batch = next(self.qa_iter)\n",
    "            except StopIteration:\n",
    "                batch = next(self.ner_iter)\n",
    "        \n",
    "        self.current_batch += 1\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_batches\n",
    "\n",
    "# Create multi-task dataloaders\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = MultiTaskDataLoader(ner_train_dataset, qa_train_dataset, batch_size=BATCH_SIZE)\n",
    "print(f\"Multi-task train loader created with {len(train_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582cebf5",
   "metadata": {},
   "source": [
    "## 10. Multi-Task Model Definition\n",
    "\n",
    "The core of our implementation: shared BERT encoder with task-specific heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_checkpoint, num_ner_labels):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        \n",
    "        # Shared BERT encoder\n",
    "        self.encoder = AutoModel.from_pretrained(model_checkpoint)\n",
    "        self.hidden_size = self.encoder.config.hidden_size\n",
    "        \n",
    "        # Task-specific heads\n",
    "        # NER Head: token classification\n",
    "        self.ner_head = nn.Linear(self.hidden_size, num_ner_labels)\n",
    "        self.ner_dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # QA Head: span prediction (start and end)\n",
    "        self.qa_start_head = nn.Linear(self.hidden_size, 1)\n",
    "        self.qa_end_head = nn.Linear(self.hidden_size, 1)\n",
    "        self.qa_dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, task_name, labels=None, \n",
    "                start_positions=None, end_positions=None):\n",
    "        \"\"\"\n",
    "        Forward pass that handles both NER and QA tasks.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs\n",
    "            attention_mask: Attention mask\n",
    "            task_name: 'ner' or 'qa'\n",
    "            labels: NER labels (for NER task)\n",
    "            start_positions: Answer start positions (for QA task)\n",
    "            end_positions: Answer end positions (for QA task)\n",
    "        \"\"\"\n",
    "        # Shared encoder\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        sequence_output = outputs.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        if task_name == 'ner':\n",
    "            # NER task\n",
    "            sequence_output = self.ner_dropout(sequence_output)\n",
    "            logits = self.ner_head(sequence_output)  # (batch_size, seq_len, num_labels)\n",
    "            \n",
    "            loss = None\n",
    "            if labels is not None:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                # Flatten tensors\n",
    "                loss = loss_fct(logits.view(-1, num_ner_labels), labels.view(-1))\n",
    "            \n",
    "            return {'loss': loss, 'logits': logits}\n",
    "        \n",
    "        elif task_name == 'qa':\n",
    "            # QA task\n",
    "            sequence_output = self.qa_dropout(sequence_output)\n",
    "            start_logits = self.qa_start_head(sequence_output).squeeze(-1)  # (batch_size, seq_len)\n",
    "            end_logits = self.qa_end_head(sequence_output).squeeze(-1)      # (batch_size, seq_len)\n",
    "            \n",
    "            loss = None\n",
    "            if start_positions is not None and end_positions is not None:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                start_loss = loss_fct(start_logits, start_positions)\n",
    "                end_loss = loss_fct(end_logits, end_positions)\n",
    "                loss = (start_loss + end_loss) / 2\n",
    "            \n",
    "            return {'loss': loss, 'start_logits': start_logits, 'end_logits': end_logits}\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {task_name}\")\n",
    "\n",
    "# Initialize model\n",
    "model = MultiTaskModel(model_checkpoint, num_ner_labels)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel initialized on {device}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1bae2a",
   "metadata": {},
   "source": [
    "## 11. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Loss weights (lambda values)\n",
    "LAMBDA_NER = 1.0\n",
    "LAMBDA_QA = 1.0\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Warmup steps: {warmup_steps}\")\n",
    "print(f\"  Loss weights: Œª_NER={LAMBDA_NER}, Œª_QA={LAMBDA_QA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644dee4c",
   "metadata": {},
   "source": [
    "## 12. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ner_loss_sum = 0\n",
    "    qa_loss_sum = 0\n",
    "    ner_batches = 0\n",
    "    qa_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        task = batch['task'][0]  # All items in batch have same task\n",
    "        \n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        if task == 'ner':\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                task_name='ner',\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs['loss'] * LAMBDA_NER\n",
    "            ner_loss_sum += loss.item()\n",
    "            ner_batches += 1\n",
    "            \n",
    "        else:  # QA\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                task_name='qa',\n",
    "                start_positions=start_positions,\n",
    "                end_positions=end_positions\n",
    "            )\n",
    "            \n",
    "            loss = outputs['loss'] * LAMBDA_QA\n",
    "            qa_loss_sum += loss.item()\n",
    "            qa_batches += 1\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'task': task\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_ner_loss = ner_loss_sum / ner_batches if ner_batches > 0 else 0\n",
    "    avg_qa_loss = qa_loss_sum / qa_batches if qa_batches > 0 else 0\n",
    "    \n",
    "    return avg_loss, avg_ner_loss, avg_qa_loss\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'ner_loss': [],\n",
    "    'qa_loss': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    avg_loss, avg_ner_loss, avg_qa_loss = train_epoch(\n",
    "        model, train_loader, optimizer, scheduler, device\n",
    "    )\n",
    "    \n",
    "    history['train_loss'].append(avg_loss)\n",
    "    history['ner_loss'].append(avg_ner_loss)\n",
    "    history['qa_loss'].append(avg_qa_loss)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Average Total Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Average NER Loss: {avg_ner_loss:.4f}\")\n",
    "    print(f\"  Average QA Loss: {avg_qa_loss:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7487822",
   "metadata": {},
   "source": [
    "## 13. Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fb500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ner(model, dataset, device, batch_size=16):\n",
    "    \"\"\"\n",
    "    Evaluate NER performance using seqeval F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating NER\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                task_name='ner'\n",
    "            )\n",
    "            \n",
    "            predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "            \n",
    "            # Convert to CPU and numpy\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            \n",
    "            # Convert to label strings (ignore -100)\n",
    "            for pred, label in zip(predictions, labels):\n",
    "                pred_labels = []\n",
    "                true_labels = []\n",
    "                for p, l in zip(pred, label):\n",
    "                    if l != -100:\n",
    "                        pred_labels.append(id2label[p])\n",
    "                        true_labels.append(id2label[l])\n",
    "                all_predictions.append(pred_labels)\n",
    "                all_labels.append(true_labels)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = ner_f1_score(all_labels, all_predictions)\n",
    "    \n",
    "    return f1, all_predictions, all_labels\n",
    "\n",
    "\n",
    "def evaluate_qa(model, dataset, device, batch_size=16):\n",
    "    \"\"\"\n",
    "    Evaluate QA performance using exact match and F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    exact_matches = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating QA\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                task_name='qa'\n",
    "            )\n",
    "            \n",
    "            pred_start = torch.argmax(outputs['start_logits'], dim=-1)\n",
    "            pred_end = torch.argmax(outputs['end_logits'], dim=-1)\n",
    "            \n",
    "            # Calculate exact matches\n",
    "            exact_match = ((pred_start == start_positions) & (pred_end == end_positions)).sum().item()\n",
    "            exact_matches += exact_match\n",
    "            total += input_ids.size(0)\n",
    "    \n",
    "    exact_match_score = exact_matches / total if total > 0 else 0\n",
    "    \n",
    "    return exact_match_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c9ef3",
   "metadata": {},
   "source": [
    "## 14. Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Evaluation on Validation Sets\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Evaluate NER\n",
    "print(\"Evaluating NER task...\")\n",
    "ner_f1, ner_preds, ner_labels = evaluate_ner(model, ner_val_dataset, device)\n",
    "print(f\"\\nNER F1-Score: {ner_f1:.4f}\")\n",
    "\n",
    "# Show detailed NER report\n",
    "print(\"\\nDetailed NER Classification Report:\")\n",
    "print(classification_report(ner_labels, ner_preds))\n",
    "\n",
    "# Evaluate QA\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"Evaluating QA task...\")\n",
    "qa_em = evaluate_qa(model, qa_val_dataset, device)\n",
    "print(f\"\\nQA Exact Match Score: {qa_em:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Evaluation Complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ac374",
   "metadata": {},
   "source": [
    "## 15. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training losses\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], marker='o')\n",
    "plt.title('Total Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['ner_loss'], marker='o', color='green')\n",
    "plt.title('NER Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['qa_loss'], marker='o', color='orange')\n",
    "plt.title('QA Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d0ee6",
   "metadata": {},
   "source": [
    "## 16. Inference Examples\n",
    "\n",
    "### 16.1 NER Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8aadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ner(text, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Predict NER tags for a given text.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    input_ids = tokens['input_ids'].to(device)\n",
    "    attention_mask = tokens['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            task_name='ner'\n",
    "        )\n",
    "    \n",
    "    predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "    predicted_labels = [id2label[p.item()] for p in predictions[0]]\n",
    "    \n",
    "    # Get tokens\n",
    "    word_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    # Filter out special tokens and combine\n",
    "    result = []\n",
    "    for token, label in zip(word_tokens, predicted_labels):\n",
    "        if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "            result.append((token, label))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test NER inference\n",
    "test_sentence = \"Apple Inc. is planning to open a new store in New York City next month.\"\n",
    "print(f\"Input: {test_sentence}\\n\")\n",
    "print(\"NER Predictions:\")\n",
    "ner_results = predict_ner(test_sentence, model, tokenizer, device)\n",
    "for token, label in ner_results:\n",
    "    if label != 'O':  # Only show named entities\n",
    "        print(f\"  {token:15s} -> {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b670a",
   "metadata": {},
   "source": [
    "### 16.1.1 Additional NER Test Cases\n",
    "\n",
    "Let's test the model with diverse sentences containing different entity types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ner_results(text, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Display NER results in a formatted way with color-coded entity types.\n",
    "    \"\"\"\n",
    "    print(f\"üìù Input: {text}\\n\")\n",
    "    \n",
    "    results = predict_ner(text, model, tokenizer, device)\n",
    "    \n",
    "    # Group consecutive tokens of the same entity\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    current_tokens = []\n",
    "    \n",
    "    for token, label in results:\n",
    "        if label.startswith('B-'):\n",
    "            # Save previous entity if exists\n",
    "            if current_entity:\n",
    "                entities.append((current_entity, ' '.join(current_tokens)))\n",
    "            # Start new entity\n",
    "            current_entity = label[2:]  # Remove 'B-' prefix\n",
    "            current_tokens = [token.replace('##', '')]\n",
    "        elif label.startswith('I-') and current_entity:\n",
    "            # Continue current entity\n",
    "            current_tokens.append(token.replace('##', ''))\n",
    "        else:\n",
    "            # Not an entity or end of entity\n",
    "            if current_entity:\n",
    "                entities.append((current_entity, ' '.join(current_tokens)))\n",
    "                current_entity = None\n",
    "                current_tokens = []\n",
    "    \n",
    "    # Don't forget the last entity\n",
    "    if current_entity:\n",
    "        entities.append((current_entity, ' '.join(current_tokens)))\n",
    "    \n",
    "    # Display results\n",
    "    if entities:\n",
    "        print(\"‚úÖ Named Entities Found:\")\n",
    "        entity_symbols = {\n",
    "            'PER': 'üë§',\n",
    "            'ORG': 'üè¢',\n",
    "            'LOC': 'üìç',\n",
    "            'MISC': 'üîñ'\n",
    "        }\n",
    "        for entity_type, entity_text in entities:\n",
    "            symbol = entity_symbols.get(entity_type, 'üîπ')\n",
    "            print(f\"  {symbol} {entity_text:30s} ‚Üí {entity_type}\")\n",
    "    else:\n",
    "        print(\"‚ùå No named entities detected\")\n",
    "    print(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST SUITE: Diverse NER Examples\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üß™ COMPREHENSIVE NER TESTING SUITE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Test 1: Business & Technology\n",
    "print(\"TEST 1: Business & Technology Entities\")\n",
    "print(\"=\"*70)\n",
    "test1 = \"Microsoft and Google are competing in artificial intelligence research in Seattle.\"\n",
    "display_ner_results(test1, model, tokenizer, device)\n",
    "\n",
    "# Test 2: People & Organizations\n",
    "print(\"TEST 2: People & Organizations\")\n",
    "print(\"=\"*70)\n",
    "test2 = \"Elon Musk, CEO of Tesla and SpaceX, announced plans to visit NASA headquarters.\"\n",
    "display_ner_results(test2, model, tokenizer, device)\n",
    "\n",
    "# Test 3: Geography & Locations\n",
    "print(\"TEST 3: Geography & International Locations\")\n",
    "print(\"=\"*70)\n",
    "test3 = \"The conference will be held in Tokyo, Japan, with speakers from London and Berlin.\"\n",
    "display_ner_results(test3, model, tokenizer, device)\n",
    "\n",
    "# Test 4: Historical Figures\n",
    "print(\"TEST 4: Historical Context\")\n",
    "print(\"=\"*70)\n",
    "test4 = \"Albert Einstein worked at Princeton University after leaving Germany during World War II.\"\n",
    "display_ner_results(test4, model, tokenizer, device)\n",
    "\n",
    "# Test 5: Sports\n",
    "print(\"TEST 5: Sports Entities\")\n",
    "print(\"=\"*70)\n",
    "test5 = \"Lionel Messi played for Barcelona before joining Paris Saint-Germain in France.\"\n",
    "display_ner_results(test5, model, tokenizer, device)\n",
    "\n",
    "# Test 6: Mixed Complex Entities\n",
    "print(\"TEST 6: Complex Mixed Entities\")\n",
    "print(\"=\"*70)\n",
    "test6 = \"The United Nations meeting in Geneva was attended by representatives from India, Brazil, and Australia.\"\n",
    "display_ner_results(test6, model, tokenizer, device)\n",
    "\n",
    "# Test 7: Academic & Research\n",
    "print(\"TEST 7: Academic & Research Context\")\n",
    "print(\"=\"*70)\n",
    "test7 = \"Researchers at Stanford University and MIT are collaborating on quantum computing projects.\"\n",
    "display_ner_results(test7, model, tokenizer, device)\n",
    "\n",
    "# Test 8: Finance & Markets\n",
    "print(\"TEST 8: Financial Entities\")\n",
    "print(\"=\"*70)\n",
    "test8 = \"Goldman Sachs and JPMorgan Chase reported strong earnings from their operations in New York.\"\n",
    "display_ner_results(test8, model, tokenizer, device)\n",
    "\n",
    "# Test 9: Media & Entertainment\n",
    "print(\"TEST 9: Media & Entertainment\")\n",
    "print(\"=\"*70)\n",
    "test9 = \"Netflix and Disney are producing new content in Los Angeles and Atlanta studios.\"\n",
    "display_ner_results(test9, model, tokenizer, device)\n",
    "\n",
    "# Test 10: Government & Politics\n",
    "print(\"TEST 10: Government & Politics\")\n",
    "print(\"=\"*70)\n",
    "test10 = \"The European Parliament in Brussels discussed trade agreements with China and Canada.\"\n",
    "display_ner_results(test10, model, tokenizer, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ú® NER TESTING COMPLETE - Model Performance Summary\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìä Entity Types Tested:\")\n",
    "print(\"  ‚Ä¢ Organizations (Companies, Universities, Government Bodies)\")\n",
    "print(\"  ‚Ä¢ Locations (Cities, Countries, Regions)\")\n",
    "print(\"  ‚Ä¢ Persons (CEOs, Historical Figures, Athletes)\")\n",
    "print(\"  ‚Ä¢ Miscellaneous (Events, Products, etc.)\")\n",
    "print(\"\\nüí° The model uses IOB (Inside-Outside-Beginning) tagging scheme:\")\n",
    "print(\"  ‚Ä¢ B-XXX: Beginning of entity type XXX\")\n",
    "print(\"  ‚Ä¢ I-XXX: Inside (continuation) of entity type XXX\")\n",
    "print(\"  ‚Ä¢ O: Outside any named entity (not displayed in filtered output)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17683218",
   "metadata": {},
   "source": [
    "### 16.2 QA Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_qa(question, context, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Predict answer for a given question and context.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=384\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            task_name='qa'\n",
    "        )\n",
    "    \n",
    "    # Get start and end positions\n",
    "    start_idx = torch.argmax(outputs['start_logits'], dim=-1).item()\n",
    "    end_idx = torch.argmax(outputs['end_logits'], dim=-1).item()\n",
    "    \n",
    "    # Extract answer\n",
    "    answer_tokens = input_ids[0][start_idx:end_idx+1]\n",
    "    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return answer, start_idx, end_idx\n",
    "\n",
    "# Test QA inference\n",
    "test_context = \"\"\"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. \n",
    "It is named after the engineer Gustave Eiffel, whose company designed and built the tower. \n",
    "Constructed from 1887 to 1889, it was initially criticised by some of France's leading artists and intellectuals. \n",
    "The tower is 330 metres tall, about the same height as an 81-storey building.\"\"\"\n",
    "\n",
    "test_question = \"How tall is the Eiffel Tower?\"\n",
    "\n",
    "print(f\"Context: {test_context}\\n\")\n",
    "print(f\"Question: {test_question}\\n\")\n",
    "\n",
    "answer, start, end = predict_qa(test_question, test_context, model, tokenizer, device)\n",
    "print(f\"Predicted Answer: {answer}\")\n",
    "print(f\"Position: tokens {start} to {end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d9af3",
   "metadata": {},
   "source": [
    "### 16.3 Additional QA Tests\n",
    "\n",
    "Let's test the model with more diverse questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645da86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Technology/Science Question\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 1: Technology Question\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "context1 = \"\"\"Artificial Intelligence (AI) is intelligence demonstrated by machines, \n",
    "as opposed to natural intelligence displayed by animals including humans. \n",
    "Leading AI textbooks define the field as the study of intelligent agents: any system \n",
    "that perceives its environment and takes actions that maximize its chance of achieving its goals. \n",
    "The term artificial intelligence was first coined by John McCarthy in 1956.\"\"\"\n",
    "\n",
    "question1 = \"Who coined the term artificial intelligence?\"\n",
    "\n",
    "print(f\"\\nContext: {context1}\\n\")\n",
    "print(f\"Question: {question1}\\n\")\n",
    "\n",
    "answer1, start1, end1 = predict_qa(question1, context1, model, tokenizer, device)\n",
    "print(f\"Predicted Answer: {answer1}\")\n",
    "print(f\"Position: tokens {start1} to {end1}\")\n",
    "\n",
    "\n",
    "# Test 2: Historical Question\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"TEST 2: Historical Question\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "context2 = \"\"\"The French Revolution was a period of radical political and societal change \n",
    "in France that began with the Estates General of 1789 and ended with the formation of the \n",
    "French Consulate in November 1799. The revolution was driven by widespread economic hardship, \n",
    "social inequality, and Enlightenment ideals. King Louis XVI was executed in 1793.\"\"\"\n",
    "\n",
    "question2 = \"When was King Louis XVI executed?\"\n",
    "\n",
    "print(f\"\\nContext: {context2}\\n\")\n",
    "print(f\"Question: {question2}\\n\")\n",
    "\n",
    "answer2, start2, end2 = predict_qa(question2, context2, model, tokenizer, device)\n",
    "print(f\"Predicted Answer: {answer2}\")\n",
    "print(f\"Position: tokens {start2} to {end2}\")\n",
    "\n",
    "\n",
    "# Test 3: Geography Question\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"TEST 3: Geography Question\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "context3 = \"\"\"Mount Everest is Earth's highest mountain above sea level, located in the \n",
    "Mahalangur Himal sub-range of the Himalayas. The China‚ÄìNepal border runs across its summit point. \n",
    "Its elevation of 8,848.86 metres was most recently established in 2020 by the Chinese and Nepali \n",
    "authorities. The mountain was first successfully climbed by Edmund Hillary and Tenzing Norgay in 1953.\"\"\"\n",
    "\n",
    "question3 = \"What is the elevation of Mount Everest?\"\n",
    "\n",
    "print(f\"\\nContext: {context3}\\n\")\n",
    "print(f\"Question: {question3}\\n\")\n",
    "\n",
    "answer3, start3, end3 = predict_qa(question3, context3, model, tokenizer, device)\n",
    "print(f\"Predicted Answer: {answer3}\")\n",
    "print(f\"Position: tokens {start3} to {end3}\")\n",
    "\n",
    "\n",
    "# Test 4: Science Question (Biology)\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"TEST 4: Biology Question\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "context4 = \"\"\"DNA, or deoxyribonucleic acid, is the hereditary material in humans and \n",
    "almost all other organisms. Nearly every cell in a person's body has the same DNA. \n",
    "The information in DNA is stored as a code made up of four chemical bases: adenine (A), \n",
    "guanine (G), cytosine (C), and thymine (T). Human DNA consists of about 3 billion bases, \n",
    "and more than 99 percent of those bases are the same in all people.\"\"\"\n",
    "\n",
    "question4 = \"How many bases does human DNA consist of?\"\n",
    "\n",
    "print(f\"\\nContext: {context4}\\n\")\n",
    "print(f\"Question: {question4}\\n\")\n",
    "\n",
    "answer4, start4, end4 = predict_qa(question4, context4, model, tokenizer, device)\n",
    "print(f\"Predicted Answer: {answer4}\")\n",
    "print(f\"Position: tokens {start4} to {end4}\")\n",
    "\n",
    "\n",
    "# Test 5: Simple \"Who\" Question\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"TEST 5: Simple Who Question\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "context5 = \"\"\"Albert Einstein was a German-born theoretical physicist, widely acknowledged \n",
    "to be one of the greatest and most influential physicists of all time. Einstein is best known \n",
    "for developing the theory of relativity, but he also made important contributions to the \n",
    "development of the theory of quantum mechanics. He received the Nobel Prize in Physics in 1921.\"\"\"\n",
    "\n",
    "question5 = \"When did Einstein receive the Nobel Prize?\"\n",
    "\n",
    "print(f\"\\nContext: {context5}\\n\")\n",
    "print(f\"Question: {question5}\\n\")\n",
    "\n",
    "answer5, start5, end5 = predict_qa(question5, context5, model, tokenizer, device)\n",
    "print(f\"Predicted Answer: {answer5}\")\n",
    "print(f\"Position: tokens {start5} to {end5}\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"QA TESTING COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dff40a",
   "metadata": {},
   "source": [
    "## 17. Save Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "save_path = \"multitask_ner_qa_model.pt\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'history': history,\n",
    "    'config': {\n",
    "        'model_checkpoint': model_checkpoint,\n",
    "        'num_ner_labels': num_ner_labels,\n",
    "        'lambda_ner': LAMBDA_NER,\n",
    "        'lambda_qa': LAMBDA_QA\n",
    "    }\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# To load the model later:\n",
    "# checkpoint = torch.load(save_path)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# history = checkpoint['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625e67e",
   "metadata": {},
   "source": [
    "## 18. Summary & Next Steps\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "‚úÖ Built a multi-task learning model with:\n",
    "- Shared BERT encoder for both tasks\n",
    "- Task-specific heads for NER and QA\n",
    "- Custom multi-task dataloader\n",
    "- Weighted loss function\n",
    "\n",
    "‚úÖ Trained on:\n",
    "- CoNLL-2003 (NER)\n",
    "- SQuAD (QA)\n",
    "\n",
    "‚úÖ Evaluated performance:\n",
    "- NER: F1-score\n",
    "- QA: Exact Match score\n",
    "\n",
    "### Potential Extensions:\n",
    "\n",
    "1. **Loss Balancing**: Experiment with different Œª values or implement GradNorm\n",
    "2. **Architecture**: Try soft parameter sharing or adapter layers\n",
    "3. **PEFT**: Implement LoRA for parameter-efficient fine-tuning\n",
    "4. **More Data**: Train on full datasets for better performance\n",
    "5. **Additional Tasks**: Add more NLP tasks (sentiment analysis, text classification, etc.)\n",
    "6. **Model Selection**: Try different base models (RoBERTa, ALBERT, etc.)\n",
    "\n",
    "### Key Learnings:\n",
    "\n",
    "- Multi-task learning enables knowledge sharing between related tasks\n",
    "- Hard parameter sharing is efficient and effective\n",
    "- Careful data preprocessing is crucial for multi-task models\n",
    "- Loss balancing can significantly impact performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
